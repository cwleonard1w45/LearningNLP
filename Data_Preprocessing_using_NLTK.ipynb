{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyObZziyRCmeJsEVCMRPIGVn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cwleonard1w45/LearningNLP/blob/main/Data_Preprocessing_using_NLTK.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Natural language Processing Data Preprocessing using NLTK\n",
        "\n",
        "> Importing necessary libraries\n",
        "\n"
      ],
      "metadata": {
        "id": "juLsMEtIy_YC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk"
      ],
      "metadata": {
        "id": "dHWceqxqrMED"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenization\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "> The process of splitting text into individual units\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gK2CscvbDt8i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Sentence Tokenization"
      ],
      "metadata": {
        "id": "exfUKgudEx69"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "text = \"Hello, world! How are you doing? This is a test sentence. NLTK is great.\"\n",
        "sentences=sent_tokenize(text)\n",
        "print(sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zILmtTPnDoEg",
        "outputId": "d53a4425-3eb9-4048-965b-bc399449dc6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello, world!', 'How are you doing?', 'This is a test sentence.', 'NLTK is great.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Word Tokenization"
      ],
      "metadata": {
        "id": "rv_pVzrsE6rD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "tokens= word_tokenize(text)\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ye-PkltAE6Vm",
        "outputId": "95c3e535-945c-4a59-82e7-bd2731efe95a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello', ',', 'world', '!', 'How', 'are', 'you', 'doing', '?', 'This', 'is', 'a', 'test', 'sentence', '.', 'NLTK', 'is', 'great', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stemming\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "> Reducing words to their root form\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6lL42cpFGWZy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "stemmer= PorterStemmer()"
      ],
      "metadata": {
        "id": "-3T_22kJGZgb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = ['happy', 'happier', 'happiness', 'joyfull', 'skating']\n",
        "for base_word  in words:\n",
        "  print(base_word,'becomes',stemmer.stem(base_word))"
      ],
      "metadata": {
        "id": "k3TRJHH1JYUa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> As you can see by the results stemming doesn't have language and its grammerly context hence its produces words like \"Happi\".\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HtM-JP9PwfNV"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YGW---V9we9M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h4-LH2bGzjGL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}